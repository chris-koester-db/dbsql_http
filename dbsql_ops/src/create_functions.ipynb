{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85a9d4dc-ad42-4000-8c50-68a84d8007ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Intro\n",
    "An [HTTP connection](https://docs.databricks.com/aws/en/sql/language-manual/sql-ref-syntax-ddl-create-connection) must be created before using the functions in this notebook.\n",
    "\n",
    "The default connection name is `databricks_api`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70170064-1d65-487b-ac2f-6e827fedd7df",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Set Catalog & Schema"
    }
   },
   "outputs": [],
   "source": [
    "use catalog identifier(:catalog);\n",
    "use schema identifier(:schema);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "acf7b10e-acf7-4ff2-9a79-c66898b18b09",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## SQL Warehouses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4d60c15-b09f-4ab1-8491-45df73a08c74",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Get SQL Warehouse Permissions"
    }
   },
   "outputs": [],
   "source": [
    "-- https://docs.databricks.com/api/workspace/warehouses/getpermissions\n",
    "create or replace function get_warehouse_permissions(\n",
    "  warehouse_id string\n",
    ")\n",
    "comment 'Gets the permissions of a SQL warehouse. SQL warehouses can inherit permissions from their root object. https://docs.databricks.com/api/workspace/warehouses/getpermissions'\n",
    "return\n",
    "select\n",
    "  http_request(\n",
    "    conn => 'databricks_api',\n",
    "    method => 'GET',\n",
    "    path => concat('2.0/permissions/warehouses/', warehouse_id)\n",
    "  ).text as resp\n",
    "|> select\n",
    "     from_json(\n",
    "       resp,\n",
    "       'STRUCT<access_control_list: ARRAY<STRUCT<all_permissions: ARRAY<STRUCT<inherited: BOOLEAN, inherited_from_object: ARRAY<STRING>, permission_level: STRING>>, display_name: STRING, group_name: STRING, service_principal_name: STRING, user_name: STRING>>, object_id: STRING, object_type: STRING>'\n",
    "     ) as resp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8eb3e21-042a-40fc-9c13-8e1cf8d4b5b6",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Set SQL Warehouse Permissions"
    }
   },
   "outputs": [],
   "source": [
    "-- https://docs.databricks.com/api/workspace/warehouses/setpermissions\n",
    "create or replace function set_warehouse_permissions(\n",
    "  warehouse_id string,\n",
    "  access_control_list string\n",
    ")\n",
    "comment 'Sets permissions on an object, replacing existing permissions if they exist. Deletes all direct permissions if none are specified. Objects can inherit permissions from their root object. https://docs.databricks.com/api/workspace/warehouses/setpermissions'\n",
    "return\n",
    "select\n",
    "  http_request(\n",
    "    conn => 'databricks_api',\n",
    "    method => 'PUT',\n",
    "    path => concat('2.0/permissions/warehouses/', warehouse_id),\n",
    "    json => access_control_list\n",
    "  ).text as resp\n",
    "|> select\n",
    "     from_json(\n",
    "       resp,\n",
    "       'STRUCT<access_control_list: ARRAY<STRUCT<all_permissions: ARRAY<STRUCT<inherited: BOOLEAN, inherited_from_object: ARRAY<STRING>, permission_level: STRING>>, display_name: STRING, group_name: STRING, service_principal_name: STRING, user_name: STRING>>, object_id: STRING, object_type: STRING>'\n",
    "     ) as resp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92d99afd-7969-4ca4-8bdc-66d0aad94fc7",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Update SQL Warehouse Permissions"
    }
   },
   "outputs": [],
   "source": [
    "-- https://docs.databricks.com/api/workspace/warehouses/updatepermissions\n",
    "create or replace function update_warehouse_permissions(\n",
    "  warehouse_id string,\n",
    "  access_control_list string\n",
    ")\n",
    "comment 'Updates the permissions on a SQL warehouse. SQL warehouses can inherit permissions from their root object. https://docs.databricks.com/api/workspace/warehouses/updatepermissions'\n",
    "return\n",
    "select\n",
    "  http_request(\n",
    "    conn => 'databricks_api',\n",
    "    method => 'PATCH',\n",
    "    path => concat('2.0/permissions/warehouses/', warehouse_id),\n",
    "    json => access_control_list\n",
    "  ).text as resp\n",
    "|> select\n",
    "     from_json(\n",
    "       resp,\n",
    "       'STRUCT<access_control_list: ARRAY<STRUCT<all_permissions: ARRAY<STRUCT<inherited: BOOLEAN, inherited_from_object: ARRAY<STRING>, permission_level: STRING>>, display_name: STRING, group_name: STRING, service_principal_name: STRING, user_name: STRING>>, object_id: STRING, object_type: STRING>'\n",
    "     ) as resp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "988050c9-ec3e-4b6b-94fb-c312806af882",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- https://docs.databricks.com/api/workspace/warehouses/getpermissionlevels\n",
    "create or replace function get_warehouse_permission_levels(\n",
    "  warehouse_id string\n",
    ")\n",
    "comment 'Gets the permission levels that a user can have on an object. https://docs.databricks.com/api/workspace/warehouses/getpermissionlevels'\n",
    "return\n",
    "select\n",
    "  http_request(\n",
    "    conn => 'databricks_api',\n",
    "    method => 'GET',\n",
    "    path => concat('2.0/permissions/warehouses/', warehouse_id, '/permissionLevels')\n",
    "  ).text as resp\n",
    "|> select\n",
    "     from_json(\n",
    "       resp,\n",
    "       'STRUCT<permission_levels: ARRAY<STRUCT<description: STRING, permission_level: STRING>>>'\n",
    "     ) as resp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6b71f47-09ee-494e-b7cf-f67125aa756c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "List Warehouses"
    }
   },
   "outputs": [],
   "source": [
    "-- https://docs.databricks.com/api/workspace/warehouses/list\n",
    "create or replace function list_warehouses(\n",
    "  run_as_user_id int default null\n",
    ")\n",
    "comment 'Lists all SQL warehouses that a user has manager permissions on. https://docs.databricks.com/api/workspace/warehouses/list'\n",
    "return\n",
    "select\n",
    "  http_request(\n",
    "    conn => 'databricks_api',\n",
    "    method => 'GET',\n",
    "    path => '2.0/sql/warehouses',\n",
    "    json => \n",
    "      to_json(\n",
    "        named_struct(\n",
    "          'run_as_user_id', run_as_user_id\n",
    "        )\n",
    "      )\n",
    "  ).text as resp\n",
    "|> select\n",
    "     from_json(\n",
    "       resp,\n",
    "       'STRUCT<warehouses: ARRAY<STRUCT<auto_stop_mins: STRING, channel: STRUCT<dbsql_version: STRING, name: STRING>, cluster_size: STRING, creator_name: STRING, enable_photon: BOOLEAN, enable_serverless_compute: BOOLEAN, health: STRUCT<details: STRING, failure_reason: STRUCT<code: STRING, parameters: STRUCT<property1: STRING, property2: STRING>, type: STRING>, message: STRING, status: STRING, summary: STRING>, id: STRING, instance_profile_arn: STRING, jdbc_url: STRING, max_num_clusters: BIGINT, min_num_clusters: STRING, name: STRING, num_active_sessions: BIGINT, num_clusters: BIGINT, odbc_params: STRUCT<hostname: STRING, path: STRING, port: BIGINT, protocol: STRING>, spot_instance_policy: STRING, state: STRING, tags: STRUCT<custom_tags: ARRAY<STRUCT<key: STRING, value: STRING>>>, warehouse_type: STRING>>>'\n",
    "     ) as resp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0087b0f4-7c6a-4c3b-a0e1-364822a40f5b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create a Warehouse"
    }
   },
   "outputs": [],
   "source": [
    "-- https://docs.databricks.com/api/workspace/warehouses/create\n",
    "create or replace function create_warehouse(\n",
    "  auto_stop_mins int default null,\n",
    "  channel_name string default 'CHANNEL_NAME_CURRENT',\n",
    "  cluster_size string default null,\n",
    "  creator_name string default null,\n",
    "  enable_serverless_compute string default null,\n",
    "  instance_profile_arn string default null,\n",
    "  max_num_clusters int default null,\n",
    "  min_num_clusters int default null,\n",
    "  name string default null,\n",
    "  spot_instance_policy string default null,\n",
    "  custom_tags array<struct<key:string,value:string>> default null,\n",
    "  warehouse_type string default null\n",
    ")\n",
    "comment 'Creates a new SQL warehouse. https://docs.databricks.com/api/workspace/warehouses/create'\n",
    "return\n",
    "select\n",
    "  http_request(\n",
    "    conn => 'databricks_api',\n",
    "    method => 'POST',\n",
    "    path => '2.0/sql/warehouses',\n",
    "    json => \n",
    "      to_json(\n",
    "        named_struct(\n",
    "          'auto_stop_mins', auto_stop_mins,\n",
    "          'channel', named_struct(\n",
    "            'dbsql_version', null,\n",
    "            'name', channel_name\n",
    "          ),\n",
    "          'cluster_size', cluster_size,\n",
    "          'creator_name', creator_name,\n",
    "          'enable_photon', true,\n",
    "          'enable_serverless_compute', enable_serverless_compute,\n",
    "          'instance_profile_arn', instance_profile_arn,\n",
    "          'max_num_clusters', max_num_clusters,\n",
    "          'min_num_clusters', min_num_clusters,\n",
    "          'name', name,\n",
    "          'spot_instance_policy', spot_instance_policy,\n",
    "          'tags', named_struct(\n",
    "            'custom_tags', custom_tags\n",
    "          ),\n",
    "          'warehouse_type', warehouse_type\n",
    "        )\n",
    "      )\n",
    "  ).text as resp\n",
    "|> select\n",
    "     from_json(\n",
    "       resp,\n",
    "       'STRUCT<id: STRING>'\n",
    "     ) as resp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ebe1586-2eb4-4880-9950-055d4013fef1",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Get Warehouse Info"
    }
   },
   "outputs": [],
   "source": [
    "-- https://docs.databricks.com/api/workspace/warehouses/get\n",
    "create or replace function get_warehouse_info(\n",
    "  id string\n",
    ")\n",
    "comment 'Gets the information for a single SQL warehouse. https://docs.databricks.com/api/workspace/warehouses/get'\n",
    "return\n",
    "select\n",
    "  http_request(\n",
    "    conn => 'databricks_api',\n",
    "    method => 'GET',\n",
    "    path => concat('2.0/sql/warehouses/', id)\n",
    "  ).text as resp\n",
    "|> select\n",
    "     from_json(\n",
    "       resp,\n",
    "       'STRUCT<auto_stop_mins: STRING, channel: STRUCT<dbsql_version: STRING, name: STRING>, cluster_size: STRING, creator_name: STRING, enable_photon: BOOLEAN, enable_serverless_compute: BOOLEAN, health: STRUCT<details: STRING, failure_reason: STRUCT<code: STRING, parameters: STRUCT<property1: STRING, property2: STRING>, type: STRING>, message: STRING, status: STRING, summary: STRING>, id: STRING, instance_profile_arn: STRING, jdbc_url: STRING, max_num_clusters: BIGINT, min_num_clusters: STRING, name: STRING, num_active_sessions: BIGINT, num_clusters: BIGINT, odbc_params: STRUCT<hostname: STRING, path: STRING, port: BIGINT, protocol: STRING>, spot_instance_policy: STRING, state: STRING, tags: STRUCT<custom_tags: ARRAY<STRUCT<key: STRING, value: STRING>>>, warehouse_type: STRING>'\n",
    "     ) as resp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa020e9f-9d50-42a9-b2ca-7e5c9e6942dd",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Delete a Warehouse"
    }
   },
   "outputs": [],
   "source": [
    "-- https://docs.databricks.com/api/workspace/warehouses/delete\n",
    "create or replace function delete_warehouse(\n",
    "  id string\n",
    ")\n",
    "comment 'Deletes a SQL warehouse. https://docs.databricks.com/api/workspace/warehouses/delete'\n",
    "return\n",
    "select\n",
    "  http_request(\n",
    "    conn => 'databricks_api',\n",
    "    method => 'DELETE',\n",
    "    path => concat('2.0/sql/warehouses/', id)\n",
    "  ).text as resp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "486bb284-c5ff-4eb3-8952-438326305511",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Update a Warehouse"
    }
   },
   "outputs": [],
   "source": [
    "-- https://docs.databricks.com/api/workspace/warehouses/edit\n",
    "create or replace function update_warehouse(\n",
    "  id string,\n",
    "  auto_stop_mins int default null,\n",
    "  channel_name string default 'CHANNEL_NAME_CURRENT',\n",
    "  cluster_size string default null,\n",
    "  creator_name string default null,\n",
    "  enable_serverless_compute string default null,\n",
    "  instance_profile_arn string default null,\n",
    "  max_num_clusters int default null,\n",
    "  min_num_clusters int default null,\n",
    "  name string default null,\n",
    "  spot_instance_policy string default null,\n",
    "  custom_tags array<struct<key:string,value:string>> default null,\n",
    "  warehouse_type string default null\n",
    ")\n",
    "comment 'Updates the configuration for a SQL warehouse. https://docs.databricks.com/api/workspace/warehouses/edit'\n",
    "return\n",
    "select\n",
    "  http_request(\n",
    "    conn => 'databricks_api',\n",
    "    method => 'POST',\n",
    "    path => concat('2.0/sql/warehouses/', id, '/edit'),\n",
    "    json => \n",
    "      to_json(\n",
    "        named_struct(\n",
    "          'auto_stop_mins', auto_stop_mins,\n",
    "          'channel', named_struct(\n",
    "            'dbsql_version', null,\n",
    "            'name', channel_name\n",
    "          ),\n",
    "          'cluster_size', cluster_size,\n",
    "          'creator_name', creator_name,\n",
    "          'enable_photon', true,\n",
    "          'enable_serverless_compute', enable_serverless_compute,\n",
    "          'instance_profile_arn', instance_profile_arn,\n",
    "          'max_num_clusters', max_num_clusters,\n",
    "          'min_num_clusters', min_num_clusters,\n",
    "          'name', name,\n",
    "          'spot_instance_policy', spot_instance_policy,\n",
    "          'tags', named_struct(\n",
    "            'custom_tags', custom_tags\n",
    "          ),\n",
    "          'warehouse_type', warehouse_type\n",
    "        )\n",
    "      )\n",
    "  ).text as resp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9783755b-6086-418e-8d95-734c4fcd2ca4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Query History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "318c4b46-b82b-4934-8dbd-d2d177f9a50b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "List Queries"
    }
   },
   "outputs": [],
   "source": [
    "-- A python function is used only so that this solution can be reconciled using\n",
    "-- the Databricks SDK. Python and SQL functions don't return identical Unix timestamps.\n",
    "create or replace function unix_timestamp_ms(dt string)\n",
    "  returns bigint\n",
    "  deterministic\n",
    "  comment 'Returns the number of milliseconds since the Unix Epoch'\n",
    "  language python\n",
    "  as $$\n",
    "    from datetime import datetime\n",
    "    dt_object = datetime.strptime(dt, '%Y-%m-%d %H:%M:%S')\n",
    "    return int(dt_object.timestamp() * 1000)\n",
    "  $$;\n",
    "\n",
    "-- https://docs.databricks.com/api/workspace/queryhistory/list\n",
    "-- include_metrics type is string because of a bug related to boolean arguments\n",
    "create or replace function list_queries(\n",
    "  start_time_ms bigint,\n",
    "  end_time_ms bigint,\n",
    "  warehouse_ids array<string>,\n",
    "  page_token string,\n",
    "  max_results int default 100,\n",
    "  include_metrics string default 'true'\n",
    ")\n",
    "comment 'List the history of queries through SQL warehouses, and serverless compute. You can filter by user ID, warehouse ID, status, and time range. Most recently started queries are returned first (up to max_results in request). The pagination token returned in response can be used to list subsequent query statuses. https://docs.databricks.com/api/workspace/queryhistory/list'\n",
    "return\n",
    "select\n",
    "  http_request(\n",
    "    conn => 'databricks_api',\n",
    "    method => 'GET',\n",
    "    path => '2.0/sql/history/queries',\n",
    "    json => \n",
    "      to_json(\n",
    "        named_struct('filter_by',\n",
    "          named_struct('query_start_time_range',\n",
    "            named_struct('start_time_ms', start_time_ms, 'end_time_ms', end_time_ms),\n",
    "            'warehouse_ids', warehouse_ids\n",
    "          ),\n",
    "          'max_results', max_results,\n",
    "          'page_token', page_token,\n",
    "          'include_metrics', include_metrics\n",
    "        )\n",
    "      )\n",
    "  ).text as resp\n",
    "|> select\n",
    "     from_json(\n",
    "       resp,\n",
    "       'struct<has_next_page: boolean, next_page_token: string, res: array<struct<channel_used: struct<dbsql_version: string, name: string>, client_application: string, duration: bigint, endpoint_id: string, error_message: string, executed_as_user_id: bigint, executed_as_user_name: string, execution_end_time_ms: bigint, is_final: boolean, lookup_key: string, metrics: struct<compilation_time_ms: bigint, execution_time_ms: bigint, network_sent_bytes: bigint, overloading_queue_start_timestamp: bigint, photon_total_time_ms: bigint, provisioning_queue_start_timestamp: bigint, pruned_bytes: bigint, pruned_files_count: bigint, query_compilation_start_timestamp: bigint, read_bytes: bigint, read_cache_bytes: bigint, read_files_count: bigint, read_partitions_count: bigint, read_remote_bytes: bigint, result_fetch_time_ms: bigint, result_from_cache: boolean, rows_produced_count: bigint, rows_read_count: bigint, spill_to_disk_bytes: bigint, task_total_time_ms: bigint, total_time_ms: bigint, write_remote_bytes: bigint>, plans_state: string, query_end_time_ms: bigint, query_id: string, query_source: struct<alert_id: string, dashboard_id: string, genie_space_id: string, job_info: struct<job_id: string, job_run_id: string, job_task_run_id: string>, legacy_dashboard_id: string, notebook_id: string, sql_query_id: string>, query_start_time_ms: bigint, query_text: string, rows_produced: bigint, spark_ui_url: string, statement_type: string, status: string, user_id: bigint, user_name: string, warehouse_id: string>>>'\n",
    "     );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-- Function to get cluistering columns metadata with optional filtering\n",
    "-- Parameters:\n",
    "--   metadata_catalog_name (mandatory): The catalog name to filter by\n",
    "--   metadata_schema_name (optional): The schema name to filter by\n",
    "--   metadata_table_name (optional): The table name to filter by\n",
    "\n",
    "CREATE OR REPLACE FUNCTION get_clustering_metadata(\n",
    "    metadata_catalog_name STRING,\n",
    "    metadata_schema_name STRING DEFAULT NULL,\n",
    "    metadata_table_name STRING DEFAULT NULL\n",
    ")\n",
    "RETURNS TABLE (\n",
    "    table_catalog STRING,\n",
    "    table_schema STRING,\n",
    "    table_name STRING,\n",
    "    table_type STRING,\n",
    "    data_source_format STRING,\n",
    "    clustering_columns ARRAY<ARRAY<STRING>>\n",
    ")\n",
    "COMMENT 'Gets table metadata from information_schema with optional filtering by catalog, schema, and table name. Makes HTTP requests to get additional metadata from Databricks API.'\n",
    "RETURN\n",
    "SELECT\n",
    "    table_catalog,\n",
    "    table_schema,\n",
    "    table_name,\n",
    "    table_type,\n",
    "    get_json_object(resp, '$.data_source_format') AS data_source_format,\n",
    "    CASE\n",
    "        WHEN get_json_object(resp, '$.properties.clusteringColumns') IS NOT NULL THEN\n",
    "            from_json(get_json_object(resp, '$.properties.clusteringColumns'), 'array<array<string>>')\n",
    "        ELSE NULL\n",
    "    END AS clustering_columns\n",
    "FROM (\n",
    "    SELECT\n",
    "        table_catalog,\n",
    "        table_schema,\n",
    "        table_name,\n",
    "        table_type,\n",
    "        http_request(\n",
    "            conn => 'databricks_api',\n",
    "            method => 'GET',\n",
    "            path => concat('2.1/unity-catalog/tables/', table_catalog, '.', table_schema, '.', table_name)\n",
    "        ).text AS resp\n",
    "    FROM aa_catalog.information_schema.tables\n",
    "    WHERE table_catalog = metadata_catalog_name\n",
    "      AND (metadata_schema_name IS NULL OR table_schema = metadata_schema_name)\n",
    "      AND (metadata_table_name IS NULL OR table_name = metadata_table_name)\n",
    ") t;\n",
    "\n",
    "-- Example Usage\n",
    "-- select * from aa_catalog.dw_ops.get_clustering_metadata('aa_catalog') as t;\n",
    "-- select * from aa_catalog.dw_ops.get_clustering_metadata('aa_catalog', 'dw_ops') as t;\n",
    "-- select * from aa_catalog.dw_ops.get_clustering_metadata('aa_catalog', 'dw_ops', 'enrollments') as t;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alerts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-- =============================================================================\n",
    "-- CREATE ALERT FUNCTION\n",
    "-- =============================================================================\n",
    "-- \n",
    "-- Purpose: Creates Databricks alerts using SQL queries with flexible configuration\n",
    "-- API Reference: https://docs.databricks.com/api/workspace/alerts/create\n",
    "-- \n",
    "-- This function allows DBAs to create monitoring alerts for:\n",
    "-- - Data quality checks (null values, data freshness)\n",
    "-- - Performance monitoring (slow queries, high resource usage)\n",
    "-- - Error rate monitoring (application errors, system failures)\n",
    "-- - Business metrics (record counts, aggregation thresholds)\n",
    "-- \n",
    "-- =============================================================================\n",
    "-- USAGE EXAMPLES\n",
    "-- =============================================================================\n",
    "-- \n",
    "-- Basic Alert (Count Monitoring):\n",
    "-- %sql\n",
    "-- select aa_catalog.dw_ops.create_alert(\n",
    "--   display_name => 'high_error_rate_alert',\n",
    "--   query_text => 'select 25 as error_count',\n",
    "--   warehouse_id => '4b9b953939869799',\n",
    "--   comparison_operator => 'GREATER_THAN',\n",
    "--   threshold_value => 10,\n",
    "--   user_email => 'akshay.amin@databricks.com',\n",
    "--   cron_schedule => '0 */5 * * * ?',\n",
    "--   source_display => 'error_count',\n",
    "--   source_name => 'error_count',\n",
    "--   parent_path => '/Workspace/Users/akshay.amin@databricks.com/offerings/dw_ops/dbsql_http/jobs'\n",
    "-- );\n",
    "-- \n",
    "-- =============================================================================\n",
    "-- PARAMETER REFERENCE\n",
    "-- =============================================================================\n",
    "-- \n",
    "-- Required Parameters:\n",
    "-- - display_name: Unique name for the alert\n",
    "-- - query_text: SQL query that returns the value to monitor\n",
    "-- - warehouse_id: SQL warehouse ID to run the query on\n",
    "-- \n",
    "-- Optional Parameters (with defaults):\n",
    "-- - comparison_operator: GREATER_THAN, LESS_THAN, EQUAL, etc. (default: GREATER_THAN)\n",
    "-- - threshold_value: Numeric threshold to compare against (default: 0.0)\n",
    "-- - user_email: Email for notifications (default: null)\n",
    "-- - cron_schedule: Cron expression for evaluation schedule (default: '0 */15 * * * ?')\n",
    "-- - source_display/name: Column alias from query_text (default: 'value')\n",
    "-- - parent_path: Workspace path for alert location (default: '/Workspace/Users/')\n",
    "-- \n",
    "-- =============================================================================\n",
    "\n",
    "create or replace function create_alert(\n",
    "  -- Required parameters\n",
    "  display_name string,\n",
    "  query_text string, -- Example: 'select count(*) as ct from my_table'\n",
    "  warehouse_id string,\n",
    "  \n",
    "  -- Alert configuration\n",
    "  comparison_operator string default 'GREATER_THAN', -- Options: GREATER_THAN, GREATER_THAN_OR_EQUAL, LESS_THAN, LESS_THAN_OR_EQUAL, EQUAL, NOT_EQUAL\n",
    "  threshold_value double default 0.0,\n",
    "  empty_result_state string default 'UNKNOWN',\n",
    "  \n",
    "  -- Notification settings\n",
    "  user_email string default null,\n",
    "  notify_on_ok boolean default true,\n",
    "  retrigger_seconds int default 0,\n",
    "  \n",
    "  -- Schedule settings\n",
    "  cron_schedule string default '0 */15 * * * ?',\n",
    "  timezone_id string default 'UTC',\n",
    "  pause_status string default 'UNPAUSED',\n",
    "  \n",
    "  -- Optional settings\n",
    "  parent_path string default '/Workspace/Users/',\n",
    "  source_aggregation string default 'FIRST',\n",
    "  source_display string default null, -- Example: 'ct' (should match column alias in query_text)\n",
    "  source_name string default null -- Example: 'ct' (should match column alias in query_text)\n",
    ")\n",
    "comment 'Creates a Databricks alert with parameterized configuration. Allows DBAs to create alerts using SQL queries with flexible notification and scheduling options.'\n",
    "return\n",
    "select\n",
    "  http_request(\n",
    "    conn => 'databricks_api',\n",
    "    method => 'POST',\n",
    "    path => '2.0/alerts',\n",
    "    json => concat(\n",
    "      '{\"display_name\":\"', display_name, '\",',\n",
    "      '\"query_text\":\"', query_text, '\",',\n",
    "      '\"parent_path\":\"', parent_path, '\",',\n",
    "      '\"warehouse_id\":\"', warehouse_id, '\",',\n",
    "      '\"evaluation\":{\"comparison_operator\":\"', comparison_operator, '\",',\n",
    "      '\"empty_result_state\":\"', empty_result_state, '\",',\n",
    "      '\"notification\":{\"notify_on_ok\":', case when notify_on_ok then 'true' else 'false' end, ',\"retrigger_seconds\":', cast(retrigger_seconds as string), ',',\n",
    "      '\"subscriptions\":[',\n",
    "      case when user_email is not null then concat('{\"user_email\":\"', user_email, '\"}') else '' end,\n",
    "      ']}',\n",
    "      ',\"source\":{\"aggregation\":\"', source_aggregation, '\",\"display\":\"', coalesce(source_display, 'value'), '\",\"name\":\"', coalesce(source_name, 'value'), '\"}',\n",
    "      ',\"threshold\":{\"value\":{\"double_value\":', cast(threshold_value as string), '}}}',\n",
    "      ',\"schedule\":{\"pause_status\":\"', pause_status, '\",\"quartz_cron_schedule\":\"', cron_schedule, '\",\"timezone_id\":\"', timezone_id, '\"}}'\n",
    "    )\n",
    "  ).text as resp;"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "sql",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "create_functions",
   "widgets": {
    "catalog": {
     "currentValue": "users",
     "nuid": "ad432de6-512d-4b19-9fc3-f5e0e45c9053",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "main",
      "label": "01 Catalog",
      "name": "catalog",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "main",
      "label": "01 Catalog",
      "name": "catalog",
      "options": {
       "autoCreated": false,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "schema": {
     "currentValue": "chris_koester",
     "nuid": "93af6528-04ba-4ff5-9811-0aaff402f97f",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "databricks_api",
      "label": "02 Schema",
      "name": "schema",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "databricks_api",
      "label": "02 Schema",
      "name": "schema",
      "options": {
       "autoCreated": false,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    }
   }
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
