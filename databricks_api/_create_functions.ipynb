{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70170064-1d65-487b-ac2f-6e827fedd7df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "use catalog identifier(:catalog);\n",
    "use schema identifier(:schema);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aeb6004e-1dee-4111-a729-22e4961727f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Unity Catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c00f9c2b-f8e3-4028-8c71-813acb2e6b5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78cbe8ef-ae17-476b-b7b0-265bcf8510ca",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Get a Table"
    }
   },
   "outputs": [],
   "source": [
    "-- https://docs.databricks.com/api/workspace/tables/get\n",
    "-- create function if not exists get_table(table_name string)\n",
    "create or replace function get_table(table_name string)\n",
    "comment 'Gets a table from the metastore for a specific catalog and schema. https://docs.databricks.com/api/workspace/tables/get'\n",
    "return\n",
    "from (select\n",
    "  http_request(\n",
    "    conn => 'databricks_api',\n",
    "    method => 'GET',\n",
    "    path => concat('2.1/unity-catalog/tables/', table_name)\n",
    "  ).text as resp\n",
    ")\n",
    "|> select\n",
    "     from_json(\n",
    "       resp,\n",
    "       'STRUCT<access_point: STRING, browse_only: BOOLEAN, catalog_name: STRING, columns: ARRAY<STRUCT<comment: STRING, mask: STRUCT<function_name: STRING, using_column_names: ARRAY<STRING>>, name: STRING, nullable: BOOLEAN, partition_index: BIGINT, position: BIGINT, type_interval_type: STRING, type_json: STRING, type_name: STRING, type_precision: BIGINT, type_scale: BIGINT, type_text: STRING>>, comment: STRING, created_at: BIGINT, created_by: STRING, data_access_configuration_id: STRING, data_source_format: STRING, deleted_at: BIGINT, delta_runtime_properties_kvpairs: STRUCT<delta_runtime_properties: STRUCT<property1: STRING, property2: STRING>>, effective_predictive_optimization_flag: STRUCT<inherited_from_name: STRING, inherited_from_type: STRING, value: STRING>, enable_predictive_optimization: STRING, full_name: STRING, metastore_id: STRING, name: STRING, owner: STRING, pipeline_id: STRING, properties: STRUCT<property1: STRING, property2: STRING>, row_filter: STRUCT<function_name: STRING, input_column_names: ARRAY<STRING>>, schema_name: STRING, sql_path: STRING, storage_credential_name: STRING, storage_location: STRING, table_constraints: ARRAY<STRUCT<foreign_key_constraint: STRUCT<child_columns: ARRAY<STRING>, name: STRING, parent_columns: ARRAY<STRING>, parent_table: STRING>, named_table_constraint: STRUCT<name: STRING>, primary_key_constraint: STRUCT<child_columns: ARRAY<STRING>, name: STRING>>>, table_id: STRING, table_type: STRING, updated_at: BIGINT, updated_by: STRING, view_definition: STRING, view_dependencies: STRUCT<dependencies: ARRAY<STRUCT<function: STRUCT<function_full_name: STRING>, table: STRUCT<table_full_name: STRING>>>>>'\n",
    "     ) as resp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7886a9a-db7f-4722-81cb-ecd66e81e7ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# File Management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe3950fb-c86c-40e0-bd25-3fdc1cf154c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef291d38-2154-4d27-9456-6561a9f111aa",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "List Directory Contents"
    }
   },
   "outputs": [],
   "source": [
    "-- https://docs.databricks.com/api/workspace/files/listdirectorycontents\n",
    "create or replace function list_directory_contents(directory_path string)\n",
    "comment 'Returns the contents of a directory. If there is no directory at the specified path, the API returns a HTTP 404 error. https://docs.databricks.com/api/workspace/files/listdirectorycontents'\n",
    "return\n",
    "from (select\n",
    "  http_request(\n",
    "    conn => 'databricks_api',\n",
    "    method => 'GET',\n",
    "    path => concat('2.0/fs/directories', directory_path)\n",
    "  ).text as resp\n",
    ")\n",
    "|> select\n",
    "     from_json(\n",
    "       resp,\n",
    "       'STRUCT<contents: ARRAY<STRUCT<file_size: BIGINT, is_directory: BOOLEAN, last_modified: BIGINT, name: STRING, path: STRING>>>'\n",
    "     ) as resp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d3a2b55-32ba-47a6-82f7-2c99d3910962",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Databricks SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "acf7b10e-acf7-4ff2-9a79-c66898b18b09",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## SQL Warehouses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6b71f47-09ee-494e-b7cf-f67125aa756c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "List Warehouses"
    }
   },
   "outputs": [],
   "source": [
    "-- https://docs.databricks.com/api/workspace/warehouses/list\n",
    "create or replace function list_warehouses(\n",
    "  run_as_user_id int default null\n",
    ")\n",
    "comment 'Lists all SQL warehouses that a user has manager permissions on. https://docs.databricks.com/api/workspace/warehouses/list'\n",
    "return\n",
    "from (select\n",
    "  http_request(\n",
    "    conn => 'databricks_api',\n",
    "    method => 'GET',\n",
    "    path => '2.0/sql/warehouses',\n",
    "    json => \n",
    "      to_json(\n",
    "        named_struct(\n",
    "          'run_as_user_id', run_as_user_id\n",
    "        )\n",
    "      )\n",
    "  ).text as resp\n",
    ")\n",
    "|> select\n",
    "     from_json(\n",
    "       resp,\n",
    "       'STRUCT<warehouses: ARRAY<STRUCT<auto_stop_mins: STRING, channel: STRUCT<dbsql_version: STRING, name: STRING>, cluster_size: STRING, creator_name: STRING, enable_photon: BOOLEAN, enable_serverless_compute: BOOLEAN, health: STRUCT<details: STRING, failure_reason: STRUCT<code: STRING, parameters: STRUCT<property1: STRING, property2: STRING>, type: STRING>, message: STRING, status: STRING, summary: STRING>, id: STRING, instance_profile_arn: STRING, jdbc_url: STRING, max_num_clusters: BIGINT, min_num_clusters: STRING, name: STRING, num_active_sessions: BIGINT, num_clusters: BIGINT, odbc_params: STRUCT<hostname: STRING, path: STRING, port: BIGINT, protocol: STRING>, spot_instance_policy: STRING, state: STRING, tags: STRUCT<custom_tags: ARRAY<STRUCT<key: STRING, value: STRING>>>, warehouse_type: STRING>>>'\n",
    "     ) as resp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0087b0f4-7c6a-4c3b-a0e1-364822a40f5b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create a Warehouse"
    }
   },
   "outputs": [],
   "source": [
    "-- https://docs.databricks.com/api/workspace/warehouses/create\n",
    "create or replace function create_warehouse(\n",
    "  auto_stop_mins int default null,\n",
    "  channel_name string default 'CHANNEL_NAME_CURRENT',\n",
    "  cluster_size string default null,\n",
    "  creator_name string default null,\n",
    "  enable_serverless_compute string default null,\n",
    "  instance_profile_arn string default null,\n",
    "  max_num_clusters int default null,\n",
    "  min_num_clusters int default null,\n",
    "  name string default null,\n",
    "  spot_instance_policy string default null,\n",
    "  custom_tags array<struct<key:string,value:string>> default null,\n",
    "  warehouse_type string default null\n",
    ")\n",
    "comment 'Creates a new SQL warehouse. https://docs.databricks.com/api/workspace/warehouses/create'\n",
    "return\n",
    "from (select\n",
    "  http_request(\n",
    "    conn => 'databricks_api',\n",
    "    method => 'POST',\n",
    "    path => '2.0/sql/warehouses',\n",
    "    json => \n",
    "      to_json(\n",
    "        named_struct(\n",
    "          'auto_stop_mins', auto_stop_mins,\n",
    "          'channel', named_struct(\n",
    "            'dbsql_version', null,\n",
    "            'name', channel_name\n",
    "          ),\n",
    "          'cluster_size', cluster_size,\n",
    "          'creator_name', creator_name,\n",
    "          'enable_photon', true,\n",
    "          'enable_serverless_compute', enable_serverless_compute,\n",
    "          'instance_profile_arn', instance_profile_arn,\n",
    "          'max_num_clusters', max_num_clusters,\n",
    "          'min_num_clusters', min_num_clusters,\n",
    "          'name', name,\n",
    "          'spot_instance_policy', spot_instance_policy,\n",
    "          'tags', named_struct(\n",
    "            'custom_tags', custom_tags\n",
    "          ),\n",
    "          'warehouse_type', warehouse_type\n",
    "        )\n",
    "      )\n",
    "  ).text as resp\n",
    ")\n",
    "|> select\n",
    "     from_json(\n",
    "       resp,\n",
    "       'STRUCT<id: STRING>'\n",
    "     ) as resp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ebe1586-2eb4-4880-9950-055d4013fef1",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Get Warehouse Info"
    }
   },
   "outputs": [],
   "source": [
    "-- https://docs.databricks.com/api/workspace/warehouses/get\n",
    "create or replace function get_warehouse_info(\n",
    "  id string\n",
    ")\n",
    "comment 'Gets the information for a single SQL warehouse. https://docs.databricks.com/api/workspace/warehouses/get'\n",
    "return\n",
    "from (select\n",
    "  http_request(\n",
    "    conn => 'databricks_api',\n",
    "    method => 'GET',\n",
    "    path => concat('2.0/sql/warehouses/', id)\n",
    "  ).text as resp\n",
    ")\n",
    "|> select\n",
    "     from_json(\n",
    "       resp,\n",
    "       'STRUCT<auto_stop_mins: STRING, channel: STRUCT<dbsql_version: STRING, name: STRING>, cluster_size: STRING, creator_name: STRING, enable_photon: BOOLEAN, enable_serverless_compute: BOOLEAN, health: STRUCT<details: STRING, failure_reason: STRUCT<code: STRING, parameters: STRUCT<property1: STRING, property2: STRING>, type: STRING>, message: STRING, status: STRING, summary: STRING>, id: STRING, instance_profile_arn: STRING, jdbc_url: STRING, max_num_clusters: BIGINT, min_num_clusters: STRING, name: STRING, num_active_sessions: BIGINT, num_clusters: BIGINT, odbc_params: STRUCT<hostname: STRING, path: STRING, port: BIGINT, protocol: STRING>, spot_instance_policy: STRING, state: STRING, tags: STRUCT<custom_tags: ARRAY<STRUCT<key: STRING, value: STRING>>>, warehouse_type: STRING>'\n",
    "     ) as resp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa020e9f-9d50-42a9-b2ca-7e5c9e6942dd",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Delete a Warehouse"
    }
   },
   "outputs": [],
   "source": [
    "-- https://docs.databricks.com/api/workspace/warehouses/delete\n",
    "create or replace function delete_warehouse(\n",
    "  id string\n",
    ")\n",
    "comment 'Deletes a SQL warehouse. https://docs.databricks.com/api/workspace/warehouses/delete'\n",
    "return\n",
    "select\n",
    "  http_request(\n",
    "    conn => 'databricks_api',\n",
    "    method => 'DELETE',\n",
    "    path => concat('2.0/sql/warehouses/', id)\n",
    "  ).text as resp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "486bb284-c5ff-4eb3-8952-438326305511",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Update a Warehouse"
    }
   },
   "outputs": [],
   "source": [
    "-- https://docs.databricks.com/api/workspace/warehouses/edit\n",
    "create or replace function update_warehouse(\n",
    "  id string,\n",
    "  auto_stop_mins int default null,\n",
    "  channel_name string default 'CHANNEL_NAME_CURRENT',\n",
    "  cluster_size string default null,\n",
    "  creator_name string default null,\n",
    "  enable_serverless_compute string default null,\n",
    "  instance_profile_arn string default null,\n",
    "  max_num_clusters int default null,\n",
    "  min_num_clusters int default null,\n",
    "  name string default null,\n",
    "  spot_instance_policy string default null,\n",
    "  custom_tags array<struct<key:string,value:string>> default null,\n",
    "  warehouse_type string default null\n",
    ")\n",
    "comment 'Updates the configuration for a SQL warehouse. https://docs.databricks.com/api/workspace/warehouses/edit'\n",
    "return\n",
    "select\n",
    "  http_request(\n",
    "    conn => 'databricks_api',\n",
    "    method => 'POST',\n",
    "    path => concat('2.0/sql/warehouses/', id, '/edit'),\n",
    "    json => \n",
    "      to_json(\n",
    "        named_struct(\n",
    "          'auto_stop_mins', auto_stop_mins,\n",
    "          'channel', named_struct(\n",
    "            'dbsql_version', null,\n",
    "            'name', channel_name\n",
    "          ),\n",
    "          'cluster_size', cluster_size,\n",
    "          'creator_name', creator_name,\n",
    "          'enable_photon', true,\n",
    "          'enable_serverless_compute', enable_serverless_compute,\n",
    "          'instance_profile_arn', instance_profile_arn,\n",
    "          'max_num_clusters', max_num_clusters,\n",
    "          'min_num_clusters', min_num_clusters,\n",
    "          'name', name,\n",
    "          'spot_instance_policy', spot_instance_policy,\n",
    "          'tags', named_struct(\n",
    "            'custom_tags', custom_tags\n",
    "          ),\n",
    "          'warehouse_type', warehouse_type\n",
    "        )\n",
    "      )\n",
    "  ).text as resp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9783755b-6086-418e-8d95-734c4fcd2ca4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Query History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "318c4b46-b82b-4934-8dbd-d2d177f9a50b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "List Queries"
    }
   },
   "outputs": [],
   "source": [
    "-- A python function is used only so that this solution can be reconciled using\n",
    "-- the Databricks SDK. Python and SQL functions don't return identical Unix timestamps.\n",
    "create or replace function unix_timestamp_ms(dt string)\n",
    "  returns bigint\n",
    "  deterministic\n",
    "  comment 'Returns the number of milliseconds since the Unix Epoch'\n",
    "  language python\n",
    "  as $$\n",
    "    from datetime import datetime\n",
    "    dt_object = datetime.strptime(dt, '%Y-%m-%d %H:%M:%S')\n",
    "    return int(dt_object.timestamp() * 1000)\n",
    "  $$;\n",
    "\n",
    "-- https://docs.databricks.com/api/workspace/queryhistory/list\n",
    "-- include_metrics type is string because of a bug related to boolean arguments\n",
    "create or replace function list_queries(\n",
    "  start_time_ms bigint,\n",
    "  end_time_ms bigint,\n",
    "  warehouse_ids array<string>,\n",
    "  page_token string,\n",
    "  max_results int default 100,\n",
    "  include_metrics string default 'true'\n",
    ")\n",
    "comment 'List the history of queries through SQL warehouses, and serverless compute. You can filter by user ID, warehouse ID, status, and time range. Most recently started queries are returned first (up to max_results in request). The pagination token returned in response can be used to list subsequent query statuses. https://docs.databricks.com/api/workspace/queryhistory/list'\n",
    "return\n",
    "from (select\n",
    "  http_request(\n",
    "    conn => 'databricks_api',\n",
    "    method => 'GET',\n",
    "    path => '2.0/sql/history/queries',\n",
    "    json => \n",
    "      to_json(\n",
    "        named_struct('filter_by',\n",
    "          named_struct('query_start_time_range',\n",
    "            named_struct('start_time_ms', start_time_ms, 'end_time_ms', end_time_ms),\n",
    "            'warehouse_ids', warehouse_ids\n",
    "          ),\n",
    "          'max_results', max_results,\n",
    "          'page_token', page_token,\n",
    "          'include_metrics', include_metrics\n",
    "        )\n",
    "      )\n",
    "  ).text as resp\n",
    ")\n",
    "|> select\n",
    "     from_json(\n",
    "       resp,\n",
    "       'struct<has_next_page: boolean, next_page_token: string, res: array<struct<channel_used: struct<dbsql_version: string, name: string>, client_application: string, duration: bigint, endpoint_id: string, error_message: string, executed_as_user_id: bigint, executed_as_user_name: string, execution_end_time_ms: bigint, is_final: boolean, lookup_key: string, metrics: struct<compilation_time_ms: bigint, execution_time_ms: bigint, network_sent_bytes: bigint, overloading_queue_start_timestamp: bigint, photon_total_time_ms: bigint, provisioning_queue_start_timestamp: bigint, pruned_bytes: bigint, pruned_files_count: bigint, query_compilation_start_timestamp: bigint, read_bytes: bigint, read_cache_bytes: bigint, read_files_count: bigint, read_partitions_count: bigint, read_remote_bytes: bigint, result_fetch_time_ms: bigint, result_from_cache: boolean, rows_produced_count: bigint, rows_read_count: bigint, spill_to_disk_bytes: bigint, task_total_time_ms: bigint, total_time_ms: bigint, write_remote_bytes: bigint>, plans_state: string, query_end_time_ms: bigint, query_id: string, query_source: struct<alert_id: string, dashboard_id: string, genie_space_id: string, job_info: struct<job_id: string, job_run_id: string, job_task_run_id: string>, legacy_dashboard_id: string, notebook_id: string, sql_query_id: string>, query_start_time_ms: bigint, query_text: string, rows_produced: bigint, spark_ui_url: string, statement_type: string, status: string, user_id: bigint, user_name: string, warehouse_id: string>>>'\n",
    "     );"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "sql",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "_create_functions",
   "widgets": {
    "catalog": {
     "currentValue": "main",
     "nuid": "ad432de6-512d-4b19-9fc3-f5e0e45c9053",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "main",
      "label": "01 Catalog",
      "name": "catalog",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "main",
      "label": "01 Catalog",
      "name": "catalog",
      "options": {
       "autoCreated": false,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "schema": {
     "currentValue": "chris_koester",
     "nuid": "93af6528-04ba-4ff5-9811-0aaff402f97f",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "databricks_api",
      "label": "02 Schema",
      "name": "schema",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "databricks_api",
      "label": "02 Schema",
      "name": "schema",
      "options": {
       "autoCreated": false,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    }
   }
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
